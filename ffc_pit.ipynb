{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a559bb02-5891-4143-8c07-3b8d31a5d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, subprocess, datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import scipy.stats as stats\n",
    "import properscoring as ps\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from scores import *\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from scipy.integrate import quad\n",
    "from scipy import interpolate\n",
    "from ipywidgets import *\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "from scipy.stats import multivariate_normal, norm\n",
    "from scipy.interpolate import make_smoothing_spline\n",
    "\n",
    "path_to_fPCA   = '/Users/Guille/Desktop/dynamic_update/software/fPCA'\n",
    "path_to_fDepth = '/Users/Guille/Desktop/dynamic_update/software/fDepth'\n",
    "path_to_data   = '/Users/Guille/Desktop/dynamic_update/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463f562c-6612-4f5b-9496-0b5b5e0d1d10",
   "metadata": {},
   "source": [
    "# Load and Processing Actual Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7518151b-00d3-4458-979e-5fcec27c3df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baffin\n",
      "(363, 288) (363, 288)\n",
      "Baffin\n",
      "(363, 288) (363, 288)\n"
     ]
    }
   ],
   "source": [
    "# Resource\n",
    "resource = 'wind'\n",
    "\n",
    "# Asset index\n",
    "i_asset = 10\n",
    "\n",
    "# Time Zone\n",
    "T_zone = 24\n",
    "\n",
    "ac_ = pd.read_csv(path_to_data + '/actuals/' + resource + '_actual_5min_site_2017.csv')\n",
    "print(ac_.columns[i_asset + 1])\n",
    "\n",
    "dates_    = ac_[['Time']].to_numpy()[T_zone*12:]\n",
    "ac_       = ac_[[ac_.columns[i_asset + 1]]].to_numpy()[T_zone*12:]\n",
    "F_ac_tr_  = ac_.reshape(int(ac_.shape[0]/288), 288)[:-1, :]\n",
    "dates_tr_ = dates_.reshape(int(dates_.shape[0]/288), 288)[:-1, :]\n",
    "print(F_ac_tr_.shape, dates_tr_.shape)\n",
    "\n",
    "ac_ = pd.read_csv(path_to_data + '/actuals/' + resource + '_actual_5min_site_2018.csv')\n",
    "print(ac_.columns[i_asset + 1])\n",
    "\n",
    "dates_    = ac_[['Time']].to_numpy()[T_zone*12:]\n",
    "ac_       = ac_[[ac_.columns[i_asset + 1]]].to_numpy()[T_zone*12:]\n",
    "F_ac_ts_  = ac_.reshape(int(ac_.shape[0]/288), 288)[:-1, :]\n",
    "dates_ts_ = dates_.reshape(int(dates_.shape[0]/288), 288)[:-1, :]\n",
    "print(F_ac_ts_.shape, dates_ts_.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969f0f92-7649-471e-922d-dcf1feef8661",
   "metadata": {},
   "source": [
    "# Load and Processing day-ahead forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1709d1d4-4ccb-463d-aea7-e5393a2ee1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baffin\n",
      "(8736,)\n",
      "(104821,)\n",
      "(8736,)\n",
      "(363, 288)\n"
     ]
    }
   ],
   "source": [
    "# Time Zone\n",
    "T_zone = 17\n",
    "\n",
    "fc_ = pd.read_csv(path_to_data + '/actuals/' + resource + '_day_ahead_forecast_2018.csv')\n",
    "print(fc_.columns[i_asset + 3])\n",
    "\n",
    "fc_ = fc_[[fc_.columns[i_asset + 3]]].to_numpy()[T_zone:-(24 - T_zone)][:, 0]\n",
    "print(fc_.shape)\n",
    "\n",
    "x_ac_ = np.linspace(0, ac_.shape[0] - 1, ac_.shape[0], dtype = int)[:-11]\n",
    "x_fc_ = np.linspace(0, fc_.shape[0] - 1, fc_.shape[0], dtype = int)*12\n",
    "print(x_ac_.shape)\n",
    "print(x_fc_.shape)\n",
    "\n",
    "fc_ts_   = interpolate.interp1d(x_fc_, fc_, kind = 'linear')(x_ac_)\n",
    "fc_ts_   = fc_ts_[:-277]\n",
    "F_fc_ts_ = fc_ts_.reshape(int(fc_ts_.shape[0]/288), 288)\n",
    "print(F_fc_ts_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fc7c644f-e13a-4b8c-a8e6-88d21d7d7f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enfore max and min\n",
    "def _gen_constraint(f_, f_min, f_max):\n",
    "    f_[f_ < f_min] = f_min\n",
    "    f_[f_ > f_max] = f_max\n",
    "    return f_\n",
    "\n",
    "# Define update function\n",
    "def _update_rate(N, update_rate = 1):\n",
    "    x_ = np.linspace(0, N - 1, N)\n",
    "    w_ = np.exp(-x_/(update_rate*1e4 + 1e-6))\n",
    "    return w_\n",
    "\n",
    "# Define forget function\n",
    "def _forget_rate(N, forget_rate = 1):\n",
    "    x_ = np.linspace(0, N - 1, N)\n",
    "    w_ = np.exp(-x_*forget_rate)\n",
    "    return w_[::-1]\n",
    "\n",
    "# Calculate weighted (w_) distance between X_ and x_\n",
    "def _dist(X_, x_, w_):\n",
    "    d_ = np.zeros((X_.shape[0], ))\n",
    "    for i in range(X_.shape[0]):\n",
    "        d_[i] = w_.T @ (X_[i, :] - x_)**2\n",
    "    return d_\n",
    "\n",
    "# Radial Basis function kernel based on distance (d_)\n",
    "def _kernel(d_, length_scale):\n",
    "    w_ = np.exp(-d_/length_scale)\n",
    "    return w_/w_.sum()\n",
    "\n",
    "def _smoothing(F_, f_, lamdba):\n",
    "    x_        = np.linspace(0, f_.shape[0] - 1, f_.shape[0])\n",
    "    F_smooth_ = F_.copy()\n",
    "    f_smooth_ = make_smoothing_spline(x_, f_, lam = lamdba)(x_)\n",
    "    for i in range(F_.shape[0]):\n",
    "        F_smooth_[i, :] = make_smoothing_spline(x_, F_[i, :], lam = lamdba)(x_)\n",
    "    F_ = F_smooth_.copy()\n",
    "    f_ = f_smooth_.copy()\n",
    "    \n",
    "    return F_, f_\n",
    "\n",
    "# Fuse day-ahead forecast with real-time forecast\n",
    "def _update_forecast(F_ac_, f_hat_, fc_, update_rate):\n",
    "\n",
    "    eta_      = _update_rate(F_ac_.shape[1] + 1, update_rate = update_rate)\n",
    "    w_update_ = np.nan_to_num((eta_/eta_.max())[1:], 0.)[::-1]\n",
    "    f_update_ = f_hat_*(1. - w_update_) + fc_*w_update_\n",
    "\n",
    "    # plt.figure(figsize = (10, 2))\n",
    "    # plt.title('Trust Rate')\n",
    "    # plt.plot(w_update_)\n",
    "    # plt.ylim(-0.1,1.1)\n",
    "    # plt.show()\n",
    "\n",
    "    return f_update_\n",
    "\n",
    "# Multivariate normal forecast assumption\n",
    "def _predictive_multivariate_normal_dist(_model, fc_):\n",
    "\n",
    "    F_ = _model['F_ts_']\n",
    "    w_ = _model['weights']  \n",
    "    \n",
    "    # Mean function\n",
    "    f_hat_ = F_.T @ w_ \n",
    "\n",
    "    # Regulate mean function\n",
    "    f_hat_ = _gen_constraint(f_hat_, _model['f_min'], _model['f_max'])\n",
    "    \n",
    "    # Smoothing prediction: unobserved mean and actuals\n",
    "    if (_model['smoothing'] == 2) | (_model['smoothing'] == 3): \n",
    "        F_, f_hat_ = _smoothing(F_, f_hat_, _model['lambda'])\n",
    "        \n",
    "    # Fuse day-ahead forecast with real-time forecast\n",
    "    mu_hat_ = _update_forecast(F_, f_hat_, fc_, _model['trust_rate'])\n",
    "\n",
    "    # Covariance function\n",
    "    F_hat_ = np.repeat(mu_hat_[:, np.newaxis], F_.shape[0], axis = 1).T\n",
    "    S_hat_ = (F_ - F_hat_).T @ np.diag(w_) @ (F_ - F_hat_)\n",
    "    \n",
    "    # plt.figure(figsize = (10, 2))\n",
    "    # plt.plot(f_hat_, label = 'real-time (fc)')\n",
    "    # plt.plot(fc_, label = 'day-ahead (fc)')\n",
    "    # plt.plot(mu_hat_, label = 'update (fc)')\n",
    "    # plt.ylim(-0.1,)\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    # Define probability dist\n",
    "    _N = multivariate_normal(mu_hat_, S_hat_, allow_singular = True)\n",
    "    \n",
    "    _model['normal'] = {}\n",
    "    _model['normal']['mean']         = mu_hat_\n",
    "    _model['normal']['covariance']   = S_hat_\n",
    "    _model['normal']['distribution'] = _N\n",
    "    \n",
    "    return _model.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "bdb6a828-457c-416f-9156-9d9c42b268f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functional forecast model and functional observations\n",
    "def _ffc_fit(F_, t_event, forget_rate  = 1e6,\n",
    "                          trust_rate   = 0,\n",
    "                          length_scale = 100, \n",
    "                          lamdba       = 1, \n",
    "                          smoothing    = 0,\n",
    "                          tr_kNNs      = 0.01,\n",
    "                          n_kNNs       = 0,\n",
    "                          n_min_kNNs   = 5,\n",
    "                          n_max_kNNs   = 50,\n",
    "                          uniform_kNNs = False):\n",
    "    \n",
    "    _model = {}\n",
    "    \n",
    "    _model['f_min'] = ac_tr_.min()\n",
    "    _model['f_max'] = ac_tr_.max()\n",
    "    _model['F_tr_'] = ac_tr_[:, :t_event]\n",
    "    _model['F_ts_'] = ac_tr_[:, t_event:]\n",
    "    \n",
    "    # Forget rate:\n",
    "    # 0 - weight equal to the all past obervation time series \n",
    "    # 1 - full weight on the most recent observations\n",
    "    _model['forget_rate'] = forget_rate\n",
    "    \n",
    "    # Thrust rate to day-ahead forecast:\n",
    "    # 0 - Don't trust the day-head forecast\n",
    "    # 1 - Trust the day-ahead forecast fully\n",
    "    _model['trust_rate'] = trust_rate\n",
    "    \n",
    "    # Kernel based distance lenght-scale parameter:\n",
    "    # lenght-scale: smaller lenght-scale weights heavier closest samples\n",
    "    _model['length_scale'] = length_scale\n",
    "\n",
    "    # Number of k nearest neighbors (n_kNNs or tr_kNNs)\n",
    "    # n_kNNs: Force n to be k\n",
    "    # tr_kNNs: Adaptive thershold by weight probability\n",
    "    # * k_min: minimim number of neightbors when applied tr_kNNs\n",
    "    # * k_max: maximum number of neightbors when applied tr_kNNs\n",
    "    # uniform_kNNs: True selected samples weights uniform, False distance based kernel wegihts\n",
    "    _model['n_kNNs']       = n_kNNs\n",
    "    _model['tr_kNNs']      = tr_kNNs\n",
    "    _model['n_min_kNNs']   = n_min_kNNs\n",
    "    _model['n_max_kNNs']   = n_max_kNNs\n",
    "    _model['uniform_kNNs'] = uniform_kNNs\n",
    "    \n",
    "    # Smoothing functions:\n",
    "    # 0: Don't apply smoothing \n",
    "    # 1: Smooth observations\n",
    "    # 2: Smooth prediction\n",
    "    # 3: Smooth observations and prediction\n",
    "    # * lamdba: smoothing parameter 0 less smooth \n",
    "    _model['smoothing'] = smoothing\n",
    "    _model['lamdba']    = lamdba\n",
    "\n",
    "    # # Number of random scenarios \n",
    "    # _model['n_scens'] = n_scens\n",
    "\n",
    "    return _model\n",
    "\n",
    "# Forecast dynamic update based on functional kNNs\n",
    "def _fknn_fc_predict(_model, f_, fc_):\n",
    "    \n",
    "    F_ = _model['F_tr_']\n",
    "    \n",
    "    # Smoothing observed mean and actuals\n",
    "    if (_model['smoothing'] == 1) | (_model['smoothing'] == 3): \n",
    "        F_, f_ = _smoothing(F_, f_, _model['lambda'])\n",
    "\n",
    "    # phi: importance weights based on time distance\n",
    "    phi_ = _forget_rate(f_.shape[0], _model['forget_rate'])\n",
    "    \n",
    "    # plt.figure(figsize = (10, 2))\n",
    "    # plt.title('Forget Rate')\n",
    "    # plt.plot(phi_)\n",
    "    # plt.ylim(-0.1,1.1)\n",
    "    # plt.show()\n",
    "\n",
    "    # d: euclidian distance between samples weighted by importance weights (phi)\n",
    "    d_ = _dist(F_, f_, phi_/phi_.sum())\n",
    "    # w: normalized wieghts distance across observations based on RBF kernel distance\n",
    "    w_ = _kernel(d_, _model['length_scale'])\n",
    "        \n",
    "    # If no k-Nearest Neibors use adaptative approach\n",
    "    if _model['n_kNNs'] == 0:\n",
    "        # Find the kNNs \n",
    "        i    = int(np.sum(np.cumsum(np.sort(w_)[::-1]) < _model['tr_kNNs']))\n",
    "        idx_nn_ = w_ > np.sort(w_)[::-1][i]\n",
    "        # Enforce upper (max) and lower (min) Nearest Neibors limit\n",
    "        if (idx_nn_.sum() < _model['n_min_kNNs']):\n",
    "            idx_nn_ = w_ > np.sort(w_)[-_model['n_min_kNNs'] - 1]\n",
    "        if (idx_nn_.sum() > _model['n_max_kNNs']):\n",
    "            idx_nn_ = w_ > np.sort(w_)[-_model['n_max_kNNs'] - 1]      \n",
    "    else:\n",
    "        k = _model['n_kNNs'].copy() + 1\n",
    "        # Find the kNNs \n",
    "        idx_nn_ = w_.argsort().argsort() > w_.shape[0] - k\n",
    "        # Get equivalent threshold\n",
    "        tr_kNNs = w_[idx_nn_].min()\n",
    "\n",
    "    # Calculate kNNs weights\n",
    "    w_knn_ = np.zeros((idx_nn_.shape[0],))\n",
    "    if _model['uniform_kNNs']:\n",
    "        w_knn_[idx_nn_] = 1.\n",
    "    else:\n",
    "        w_knn_[idx_nn_] = w_[idx_nn_]\n",
    "    _model['weights'] = w_knn_/w_knn_.sum()\n",
    "\n",
    "    # Multivariate normal assumption\n",
    "    _model = _predictive_multivariate_normal_dist(_model, fc_)\n",
    "    \n",
    "    return _model\n",
    "    \n",
    "# Forecast dynamic update based on distance\n",
    "def _ffc_predict(_model, f_, fc_):\n",
    "    \n",
    "    F_ = _model['F_tr_']\n",
    "    \n",
    "    # Smoothing observed mean and actuals\n",
    "    if (_model['smoothing'] == 1) | (_model['smoothing'] == 3): \n",
    "        F_, f_ = _smoothing(F_, f_, _model['lambda'])\n",
    "\n",
    "    # phi: importance weights based on time distance\n",
    "    phi_ = _forget_rate(f_.shape[0], _model['forget_rate'])\n",
    "    \n",
    "    # plt.figure(figsize = (10, 2))\n",
    "    # plt.title('Forget Rate')\n",
    "    # plt.plot(phi_)\n",
    "    # plt.ylim(-0.1,1.1)\n",
    "    # plt.show()\n",
    "\n",
    "    # d: euclidian distance between samples weighted by importance weights (phi)\n",
    "    d_ = _dist(F_, f_, phi_/phi_.sum())\n",
    "    # w: normalized wieghts distance across observations based on RBF kernel distance\n",
    "    w_ = _kernel(d_, _model['length_scale'])\n",
    "\n",
    "    _model['weights'] = w_/w_.sum()\n",
    "\n",
    "    # Multivariate normal assumption\n",
    "    _model = _predictive_multivariate_normal_dist(_model, fc_)\n",
    "\n",
    "    return _model\n",
    "\n",
    "# Select a test sample and forecast and split into traning and test\n",
    "def _get_test_sample(F_, F_fc_ts_, i_day, t_event):\n",
    "\n",
    "    f_    = F_[i_day, :]\n",
    "    f_tr_ = F_[i_day, :t_event]\n",
    "    f_ts_ = F_[i_day, t_event:]\n",
    "    #print(f_.shape, f_tr_.shape, f_ts_.shape)\n",
    "\n",
    "    fc_    = F_fc_ts_[i_day, :]\n",
    "    fc_tr_ = F_fc_ts_[i_day, :t_event]\n",
    "    fc_ts_ = F_fc_ts_[i_day, t_event:]\n",
    "    #print(fct_.shape, fct_tr_.shape, fct_ts_.shape)\n",
    "\n",
    "    return f_tr_, fc_tr_, f_ts_, fc_ts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "33b927f1-ccf8-46da-b36d-e4356515e15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "yearday  = 50\n",
    "interval = 140\n",
    "\n",
    "f_tr_, fc_tr_, f_ts_, fc_ts_ = _get_test_sample(F_ac_ts_, F_fc_ts_, yearday, interval)\n",
    "\n",
    "_model = _ffc_fit(F_ac_tr_, interval,\n",
    "                  forget_rate  = 1,\n",
    "                  trust_rate   = 0,\n",
    "                  length_scale = 100, \n",
    "                  lamdba       = 1, \n",
    "                  smoothing    = 0,\n",
    "                  tr_kNNs      = 0.01,\n",
    "                  n_kNNs       = 0,\n",
    "                  n_min_kNNs   = 5,\n",
    "                  n_max_kNNs   = 50,\n",
    "                  uniform_kNNs = False)\n",
    "\n",
    "_model_fknn = _fknn_fc_predict(_model, f_tr_, fc_ts_)\n",
    "_model_fcc  = _ffc_predict(_model, f_tr_, fc_ts_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f2d65-7088-43c9-807f-0f293e3cd4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
